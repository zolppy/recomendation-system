{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "df69b56e"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBPY5VKDF1fC"
      },
      "source": [
        "# Define the dataset name\n",
        "dataset_name = \"tf_flowers\"\n",
        "\n",
        "# Load the dataset, splitting it into training, validation, and test sets\n",
        "# with_info=True includes dataset metadata\n",
        "# as_supervised=True returns data as (image, label) pairs\n",
        "(train_ds, validation_ds, test_ds), metadata = tfds.load(\n",
        "    dataset_name,\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "# Print information about the loaded dataset\n",
        "print(\"Dataset loaded successfully.\")\n",
        "print(f\"Dataset name: {metadata.full_name}\")\n",
        "print(f\"Number of training examples: {metadata.splits['train[:80%]'].num_examples}\")\n",
        "print(f\"Number of validation examples: {metadata.splits['train[80%:90%]'].num_examples}\")\n",
        "print(f\"Number of test examples: {metadata.splits['train[90%:]'].num_examples}\")\n",
        "print(f\"Number of classes: {metadata.features['label'].num_classes}\")\n",
        "print(f\"Class names: {metadata.features['label'].names}\")\n",
        "\n",
        "# Display a few example images from the training dataset\n",
        "print(\"\\nDisplaying a few example images:\")\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(train_ds.take(9)):\n",
        "    ax = fig.add_subplot(3, 3, i + 1)\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(metadata.features['label'].names[label.numpy()])\n",
        "    ax.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Define image dimensions for preprocessing\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "\n",
        "# Define a preprocessing function to resize and normalize images\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing, batch, and prefetch the datasets for efficient training\n",
        "train_ds = train_ds.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "validation_ds = validation_ds.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\nPreprocessing applied: images resized and normalized.\")\n",
        "print(\"Datasets batched and prefetched for efficient training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a895bb65"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the VGG16 base model with pre-trained ImageNet weights\n",
        "# include_top=False removes the classification layer\n",
        "# input_shape specifies the input image dimensions\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Get the output of the base model\n",
        "x = base_model.output\n",
        "# Flatten the output to feed into a dense layer\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Create a new model that outputs the flattened features\n",
        "feature_extraction_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "print(\"Feature Extraction Model Summary:\")\n",
        "feature_extraction_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5bbbb9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize lists to store extracted features and corresponding labels for each dataset split\n",
        "train_features = []\n",
        "train_labels = []\n",
        "validation_features = []\n",
        "validation_labels = []\n",
        "test_features = []\n",
        "test_labels = []\n",
        "\n",
        "print(\"Extracting features from training dataset...\")\n",
        "# Iterate through the training dataset, predict features using the feature extraction model\n",
        "for images, labels in train_ds:\n",
        "    features = feature_extraction_model.predict(images)\n",
        "    train_features.append(features)\n",
        "    train_labels.append(labels.numpy())\n",
        "\n",
        "print(\"Extracting features from validation dataset...\")\n",
        "# Iterate through the validation dataset, predict features\n",
        "for images, labels in validation_ds:\n",
        "    features = feature_extraction_model.predict(images)\n",
        "    validation_features.append(features)\n",
        "    validation_labels.append(labels.numpy())\n",
        "\n",
        "print(\"Extracting features from test dataset...\")\n",
        "# Iterate through the test dataset, predict features\n",
        "for images, labels in test_ds:\n",
        "    features = feature_extraction_model.predict(images)\n",
        "    test_features.append(features)\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "# Concatenate the lists of features and labels into NumPy arrays\n",
        "train_features = np.concatenate(train_features, axis=0)\n",
        "train_labels = np.concatenate(train_labels, axis=0)\n",
        "validation_features = np.concatenate(validation_features, axis=0)\n",
        "validation_labels = np.concatenate(validation_labels, axis=0)\n",
        "test_features = np.concatenate(test_features, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "print(\"\\nFeature extraction complete.\")\n",
        "print(f\"Training features shape: {train_features.shape}\")\n",
        "print(f\"Training labels shape: {train_labels.shape}\")\n",
        "print(f\"Validation features shape: {validation_features.shape}\")\n",
        "print(f\"Validation labels shape: {validation_labels.shape}\")\n",
        "print(f\"Test features shape: {test_features.shape}\")\n",
        "print(f\"Test labels shape: {test_labels.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fec7780"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_image_similarity(query_features, dataset_features):\n",
        "  \"\"\"\n",
        "  Calculates cosine similarity between a query feature vector and dataset feature vectors.\n",
        "\n",
        "  Args:\n",
        "    query_features: A NumPy array representing the feature vector of the query image.\n",
        "    dataset_features: A NumPy array representing the feature vectors of the dataset images.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array containing the cosine similarity scores between the query image\n",
        "    and each image in the dataset.\n",
        "  \"\"\"\n",
        "  # Reshape the query features to be a 2D array (required by cosine_similarity)\n",
        "  query_features = query_features.reshape(1, -1)\n",
        "  # Calculate cosine similarity between the query features and dataset features\n",
        "  similarity_scores = cosine_similarity(query_features, dataset_features)\n",
        "\n",
        "  # Return the similarity scores (removing the extra dimension)\n",
        "  return similarity_scores[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09c4c464"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def recommend_similar_images(query_features, dataset_features, dataset_info, num_recommendations):\n",
        "  \"\"\"\n",
        "  Finds the most similar images in a dataset to a query image.\n",
        "\n",
        "  Args:\n",
        "    query_features: A NumPy array representing the feature vector of the query image.\n",
        "    dataset_features: A NumPy array representing the feature vectors of the dataset images.\n",
        "    dataset_info: A list or array containing information (e.g., labels, paths)\n",
        "                  for each image in the dataset, corresponding to dataset_features.\n",
        "    num_recommendations: The number of top similar images to return.\n",
        "\n",
        "  Returns:\n",
        "    A list containing the information (from dataset_info) of the top\n",
        "    num_recommendations most similar images.\n",
        "  \"\"\"\n",
        "  # Get cosine similarity scores between the query image and all dataset images\n",
        "  similarity_scores = get_image_similarity(query_features, dataset_features)\n",
        "  # Get the indices of the top num_recommendations most similar images\n",
        "  # argsort sorts in ascending order, [::-1] reverses to get descending order\n",
        "  top_indices = np.argsort(similarity_scores)[::-1]\n",
        "  # Select the top indices\n",
        "  top_indices = top_indices[:num_recommendations]\n",
        "  # Get the information (labels in this case) for the recommended images\n",
        "  recommended_images_info = [dataset_info[i] for i in top_indices]\n",
        "\n",
        "  return recommended_images_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbfc3d2b"
      },
      "source": [
        "# Define the number of random test images to use as queries\n",
        "num_test_queries = 10\n",
        "# Select random indices from the test set\n",
        "random_indices = np.random.choice(len(test_features), num_test_queries, replace=False)\n",
        "# Get the features and labels for the selected random query images\n",
        "query_features_subset = test_features[random_indices]\n",
        "query_labels_subset = test_labels[random_indices]\n",
        "\n",
        "print(f\"Selected {num_test_queries} random images from the test set as queries.\")\n",
        "\n",
        "# Define the number of recommendations to get for each query\n",
        "num_recommendations = 10\n",
        "# Initialize a list to store the recommendations for each query\n",
        "recommendations = []\n",
        "\n",
        "print(f\"Getting {num_recommendations} recommendations from the training dataset for each query...\")\n",
        "# Iterate through the query images and get recommendations from the training dataset\n",
        "for i, query_feature in enumerate(query_features_subset):\n",
        "    recommended_info = recommend_similar_images(\n",
        "        query_feature,\n",
        "        train_features, # Use training features as the dataset to search for similar images\n",
        "        train_labels,   # Use training labels to get information about recommended images\n",
        "        num_recommendations\n",
        "    )\n",
        "    # Store the query label and the labels of the recommended images\n",
        "    recommendations.append({\n",
        "        'query_label': query_labels_subset[i],\n",
        "        'recommended_labels': recommended_info\n",
        "    })\n",
        "\n",
        "print(\"Recommendations obtained for all queries.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191d88f2"
      },
      "source": [
        "# Initialize a list to store precision scores for each query\n",
        "precision_scores = []\n",
        "\n",
        "print(\"Calculating precision for each query...\")\n",
        "# Iterate through the recommendations for each query\n",
        "for rec in recommendations:\n",
        "    query_label = rec['query_label']\n",
        "    recommended_labels = rec['recommended_labels']\n",
        "\n",
        "    # Count how many of the recommended images have the same label as the query image\n",
        "    relevant_count = sum(1 for label in recommended_labels if label == query_label)\n",
        "\n",
        "    # Calculate precision: relevant recommendations / total recommendations\n",
        "    precision = relevant_count / num_recommendations\n",
        "    precision_scores.append(precision)\n",
        "\n",
        "# Calculate the average precision across all queries\n",
        "average_precision = np.mean(precision_scores)\n",
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Number of test queries: {num_test_queries}\")\n",
        "print(f\"Number of recommendations per query: {num_recommendations}\")\n",
        "print(f\"Precision scores for each query: {precision_scores}\")\n",
        "print(f\"Average Precision: {average_precision:.4f}\")\n",
        "\n",
        "print(\"\\nDiscussion:\")\n",
        "# Provide a brief interpretation of the average precision score\n",
        "if average_precision > 0.5:\n",
        "    print(\"The recommendation system shows reasonably good performance with an average precision above 0.5, meaning more than half of the recommendations on average are of the same class as the query image.\")\n",
        "elif average_precision > 0.2:\n",
        "    print(\"The recommendation system shows moderate performance. There is room for improvement to increase the proportion of relevant recommendations.\")\n",
        "else:\n",
        "    print(\"The recommendation system's performance is relatively low. Further model training, architecture tuning, or exploring different similarity metrics might be needed.\")\n",
        "\n",
        "print(f\"\\nBased on the average precision of {average_precision:.4f}, the system's ability to retrieve visually similar images from the same class is evaluated.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}